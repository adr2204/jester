# jester

# Jester Recommender System

Este repositorio contiene el proyecto final de sistemas de recomendaci贸n, centrado en el uso del dataset **Jester**, una base de datos de puntuaciones de chistes recolectada de usuarios reales. El objetivo principal es comparar distintas t茅cnicas de recomendaci贸n y evaluar su rendimiento.

##  Dataset

- **Nombre**: Jester dataset (jester-data-1)
- **Caracter铆sticas**:
  - Puntuaciones num茅ricas continuas entre **-10** y **10**
  - Las puntuaciones faltantes est谩n marcadas como **99**
  - Contiene evaluaciones de **100 chistes** por m谩s de **73.000 usuarios** (en nuestro caso: 943 usuarios y 1682 铆tems seleccionados para evaluaci贸n)

##  T茅cnicas implementadas

Se han comparado cuatro enfoques principales para el sistema de recomendaci贸n:

1. **K-Nearest Neighbors (KNN)**  
   - Basado en similitud entre usuarios o 铆tems  
   - Uso de m茅tricas como coseno o correlaci贸n de Pearson  
   - Buena interpretaci贸n, pero limitado en escalabilidad

2. **Matrix Factorization (MF)**  
   - Factorizaci贸n de la matriz de utilidad mediante descenso por gradiente  
   - Variaci贸n de hiperpar谩metros como n煤mero de factores y tasa de aprendizaje  
   - Se evalu贸 con datos normalizados y sin normalizar

3. **Bernoulli Matrix Factorization**  
   - Modelo probabil铆stico que binariza las valoraciones (por ejemplo, likes/dislikes)  
   - Adaptado al Jester dataset mediante umbrales de satisfacci贸n  
   - Implementaci贸n optimizada con NumPy

4. **Neural Collaborative Filtering (NCF)**  
   - Modelo basado en redes neuronales profundas  
   - Combina Generalized Matrix Factorization (GMF) y Multi-Layer Perceptrons (MLP)  
   - Entrenado con PyTorch/Keras y optimizado mediante Adam  
   - Mejora la capacidad del modelo para capturar interacciones no lineales complejas

## 锔 Evaluaci贸n y m茅tricas

Las t茅cnicas se evaluaron con las siguientes m茅tricas:

- **MAE (Mean Absolute Error)**

Tambi茅n se compar贸 el rendimiento frente a una l铆nea base simple: la media global de puntuaciones.

##  An谩lisis

- Se incluy贸 un estudio sobre el impacto de los hiperpar谩metros (como el n煤mero de factores latentes o la profundidad de la red neuronal) en el rendimiento de los modelos.
- Las gr谩ficas muestran la evoluci贸n de la p茅rdida, la precisi贸n y otras m茅tricas durante el entrenamiento.
- Se discuten ventajas, limitaciones y posibles aplicaciones de cada enfoque.


